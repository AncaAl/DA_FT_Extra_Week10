{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0054bb2",
   "metadata": {},
   "source": [
    "\n",
    "# Principal Component Analysis (PCA)\n",
    "\n",
    "Principal Component Analysis (PCA) is a statistical technique used for dimensionality reduction. It transforms the data into a new coordinate system such that the greatest variance by any projection of the data comes to lie on the first coordinate (called the first principal component), the second greatest variance on the second coordinate, and so on.\n",
    "\n",
    "## Theoretical Background\n",
    "\n",
    "PCA involves the following steps:\n",
    "\n",
    "1. **Standardize the Data**: Center the data by subtracting the mean of each feature and scale to unit variance.\n",
    "2. **Covariance Matrix**: Compute the covariance matrix of the standardized data.\n",
    "3. **Eigenvalues and Eigenvectors**: Calculate the eigenvalues and eigenvectors of the covariance matrix.\n",
    "4. **Principal Components**: Sort the eigenvectors by decreasing eigenvalues and select the top k eigenvectors.\n",
    "5. **Transform Data**: Project the original data onto the selected eigenvectors to get the principal components.\n",
    "\n",
    "Mathematically, PCA can be represented as:\n",
    "\n",
    "\\[ X_{new} = X \\cdot W \\]\n",
    "\n",
    "where \\( X \\) is the original data, \\( W \\) is the matrix of selected eigenvectors, and \\( X_{new} \\) is the transformed data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe4ca30",
   "metadata": {},
   "source": [
    "\n",
    "## Hands-on Example\n",
    "\n",
    "Let's walk through a hands-on example using Python and the scikit-learn library.\n",
    "\n",
    "### Step 1: Import Libraries\n",
    "\n",
    "First, we need to import the necessary libraries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0ce82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# For this example, we will use the Iris dataset\n",
    "from sklearn.datasets import load_iris\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd84aff",
   "metadata": {},
   "source": [
    "\n",
    "### Step 2: Load and Standardize the Data\n",
    "\n",
    "We will use the Iris dataset for this example.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c933b004",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "```python\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "feature_names = iris.feature_names\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_std = scaler.fit_transform(X)\n",
    "\n",
    "# Convert to DataFrame for easier handling\n",
    "df = pd.DataFrame(X_std, columns=feature_names)\n",
    "df['target'] = y\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a1718f",
   "metadata": {},
   "source": [
    "\n",
    "### Step 3: Covariance Matrix and Eigenvalues\n",
    "\n",
    "Compute the covariance matrix and find the eigenvalues and eigenvectors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18523cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "```python\n",
    "# Compute the covariance matrix\n",
    "cov_matrix = np.cov(X_std.T)\n",
    "\n",
    "# Compute the eigenvalues and eigenvectors\n",
    "eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)\n",
    "\n",
    "# Sort the eigenvalues and corresponding eigenvectors\n",
    "sorted_idx = np.argsort(eigenvalues)[::-1]\n",
    "eigenvalues = eigenvalues[sorted_idx]\n",
    "eigenvectors = eigenvectors[:, sorted_idx]\n",
    "\n",
    "print(\"Eigenvalues:\", eigenvalues)\n",
    "print(\"Eigenvectors:\n",
    "\", eigenvectors)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a3b441",
   "metadata": {},
   "source": [
    "\n",
    "### Step 4: PCA with Scikit-learn\n",
    "\n",
    "Perform PCA using the scikit-learn library and transform the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b5d341",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "```python\n",
    "# Perform PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_std)\n",
    "\n",
    "# Create a DataFrame with the principal components\n",
    "df_pca = pd.DataFrame(X_pca, columns=['PC1', 'PC2'])\n",
    "df_pca['target'] = y\n",
    "\n",
    "# Explained variance\n",
    "print(\"Explained variance ratio:\", pca.explained_variance_ratio_)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12d66a6",
   "metadata": {},
   "source": [
    "\n",
    "### Step 5: Visualize the Result\n",
    "\n",
    "Visualize the first two principal components.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6714cb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "```python\n",
    "# Plot the first two principal components\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.scatterplot(x='PC1', y='PC2', hue='target', data=df_pca, palette='viridis', s=100)\n",
    "plt.title('PCA of Iris Dataset')\n",
    "plt.show()\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
